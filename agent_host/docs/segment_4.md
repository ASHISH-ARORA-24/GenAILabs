# Segment 4 â€“ Execution Contract (AgentHost â†” Agent Execution Flow)

## ðŸ”¥ Why this matters

Once routing decides which agent should handle a query, AgentHost must:

1. Send the agent a well-structured request
2. Agent performs its logic (MCP call, API, RAG, etc.)
3. Agent sends back a structured result
4. AgentHost forwards it to the Final Composer (LLM)

This contract ensures all agents follow the same communication rules, even though their internal logic may be completely different.

---

## 1. When Execution Starts

Execution begins only after:

- **Manual mode:** user chooses an agent
- **Auto mode:** LLM router selects an agent

So now AgentHost knows:

- `agent_name`
- `user_query`
- Any additional context

Now AgentHost must call the agent.

---

## 2. Execution Request (AgentHost â†’ Agent)

The execution request is always a structured object, not free text.

Here is the conceptual `ExecutionRequest` design:

```yaml
ExecutionRequest:
  request_id: string
  user_query: string
  routing_mode: "auto" | "manual"
  selected_agent: string         # agent decided by router or user
  parsed_parameters: object      # optional, later for advanced use
  session_context: object        # user/session metadata (optional)
  agent_instructions: string     # optional, formed by Host or router (later)
```

Let's break this down.

### 2.1 `request_id`

**Unique ID** generated by AgentHost.

- Lets AgentHost match responses to requests.
- Useful for logs, debugging, tracing.

**Example:**
```
"req-2025-12-06-123456"
```

### 2.2 `user_query`

Exact text from Streamlit.

Agent must know what the user asked.

### 2.3 `routing_mode`

So the agent can know whether:
- It was selected by LLM
- **OR** explicitly chosen by user

This can influence behavior later.

### 2.4 `selected_agent`

The name of the agent being called:
```
"DevOpsAgent"
```

This is redundant (agent already knows itself), but it enforces consistent structure across systems.

### 2.5 `parsed_parameters` (Optional, future feature)

**Right now:** leave empty (`{}`).

**Later:**
- LLM router can extract structured parameters for tools

**Example:**
```json
{
  "resource": "AzureVM",
  "days": 7
}
```

This will help with MCP tool calling.

But for **Phase 2 MVP** â†’ keep it blank.

### 2.6 `session_context` (Optional)

For future use:
- user profile
- organization
- time zone
- chat history
- preferences

For now â†’ keep as `{}`.

### 2.7 `agent_instructions` (Optional)

In advanced setups:
- LLM router may generate instructions for the agent
- e.g., "Focus on cost analysis only, ignore infra issues"

For now â†’ leave this empty.

---

## 3. Execution Response (Agent â†’ AgentHost)

After agent does its work, it must respond with a structured result.

Here is the conceptual `ExecutionResponse`:

```yaml
ExecutionResponse:
  request_id: string
  status: "success" | "error" | "partial"
  result: object | string      # structured or plain text result
  error: string (optional)
  metadata: object (optional)  # timing, cost, extra info
```

### Meaning of each field:

### 3.1 `request_id`

Must match the ID sent in `ExecutionRequest`.

Ensures AgentHost can correlate responses properly.

### 3.2 `status`

Three valid values:

#### `"success"`
Agent completed the task fully.

#### `"error"`
Agent failed due to:
- no data
- tool failure
- MCP error
- invalid query

#### `"partial"`
Agent got some data but not complete.

Useful for:
- Multi-tool agents
- Partial document RAG
- Network timeouts

### 3.3 `result`

This is the **actual output** from the agent.

It can be:
- a structured JSON
- a dictionary
- a string summary
- a list
- a table-like structure

**Important:** final LLM composer will convert this into user-friendly language, so raw or technical formats are fine.

#### Examples:

**For DevOpsAgent:**
```json
{
  "vm_costs_last_7_days": 74.33,
  "trend": "increasing",
  "recommendation": "scale down 1 runner"
}
```

**For RAGAgent:**
```json
{
  "document_summary": "RunnerScale uses ephemeral VM-based GitHub runners...",
  "sources": ["design_doc_2024.pdf"]
}
```

### 3.4 `error` (optional)

If `status = "error"`:
```
"Azure API timed out while fetching VM cost data"
```

If not an error â†’ omit.

### 3.5 `metadata` (optional)

Useful later for debugging:
- latency
- MCP tool names used
- tokens consumed
- time consumed

**Example:**
```json
{
  "duration_ms": 243,
  "tool_used": "azure_cost_report",
  "agent_version": "v0.2.0"
}
```

For MVP â†’ metadata is optional.

---

## 4. Execution Flow Summary

Putting everything together:

1. **Streamlit** sends a query + routing mode.

2. **AgentHost** selects target agent (manual or LLM router).

3. **AgentHost** builds `ExecutionRequest` and sends it to the agent.

4. **Agent** runs its logic (MCP, RAG, API, internal code).

5. **Agent** returns `ExecutionResponse` to AgentHost.

6. **AgentHost** sends:
   - `user_query`
   - `result` from agent
   - optional `usage_hints`
   
   to **Final LLM Composer**.

7. **Composer LLM** returns polished user-facing text.

8. **AgentHost** sends it back to Streamlit.

This is now a **complete execution lifecycle**.

---

## 5. README Section for Segment 4

You can add:

### Execution Contract (AgentHost â†” Agents)

**Summarize:**

- **`ExecutionRequest` fields**
- **`ExecutionResponse` fields**
- Purpose of each
- Execution flow (steps 1â€“8)

---

## âœ… Segment 4 is Now Designed

We have a clear execution contract that standardizes how AgentHost communicates with all agents, regardless of their internal implementation.
